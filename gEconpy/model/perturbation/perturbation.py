from functools import wraps
from inspect import signature

import numpy as np
import sympy as sp

from numpy.typing import ArrayLike
from scipy import linalg

from gEconpy.classes.time_aware_symbol import TimeAwareSymbol
from gEconpy.model.compile import BACKENDS, compile_function
from gEconpy.shared.utilities import eq_to_ss
from gEconpy.solvers.cycle_reduction import nb_cycle_reduction, nb_solve_shock_matrix
from gEconpy.solvers.gensys import gensys


def override_dummy_wrapper(f, param_name="not_loglin_variable"):
    """
    Wrap a function to map a parameter name to a _Dummy argument in a sympy lambdify generated function

    To have a 1d array input to a sympy lambdify function, it is necessary to use an IndexBase. IndexBase,
    unfortunately, always ends up as a Dummy value when lambdified. This wrapper finds a single dummy value
    in a function signature, and automatically maps the parameter name to it.

    Parameters
    ----------
    f: Callable
        Function generated by sympy.lambidfy, with exactly one dummy variable
    param_name: str
        Named arugment that will be mapped to the dummy in the wrapped function

    Returns
    -------
    inner: Callable
        Same as f, with a keyword argument "param_name" that maps to the Dummy input

    """
    sig = signature(f)
    f_inputs = list(sig.parameters.keys())
    dummies = [x for x in f_inputs if x.startswith("_Dummy")]
    assert len(dummies) == 1

    @wraps(f)
    def inner(*args, **kwargs):
        loglin = kwargs.pop(param_name)
        kwargs[dummies[0]] = loglin

        return f(*args, **kwargs)

    return inner


def make_all_variable_time_combinations(
    variables,
) -> tuple[list[TimeAwareSymbol], list[TimeAwareSymbol], list[TimeAwareSymbol]]:
    """
    Given a list of TimeAwareSymbols, all at time t, shift them to create all possible lags, current, and lead variables.

    Parameters
    ----------
    variables: List[TimeAwareSymbol]
        List of variables to shift.

    Returns
    -------
    lags: List[TimeAwareSymbol]
        List of variables shifted to t-1.
    now: List[TimeAwareSymbol]
        List of variables at time t.
    leads: List[TimeAwareSymbol]
        List of variables shifted to t+1.
    """
    # Set all variables to time t, remove duplicates, and sort by base name.
    now = list({x.set_t(0) for x in variables})
    now = sorted(now, key=lambda x: x.base_name)

    # Create lags and leads by shifting the time of the variables.
    lags = [x.step_backward() for x in now]
    leads = [x.step_forward() for x in now]

    return lags, now, leads


def linearize_model(
    variables: list[TimeAwareSymbol],
    equations: list[sp.Expr],
    shocks: list[sp.Symbol],
    order=1,
) -> list[sp.Matrix]:
    """
    Log-linearize a model around its steady state.

    Parameters
    ----------
    variables: List[TimeAwareSymbol]
        List of all variables in the model, expressed at time t

    equations: List[sp.Expr]
        List of equations that define the model.

    shocks: List[sp.Symbol]
        List of exogenous shocks in the model.

    order: int, default 1
        Order of the linear approximation of the model. Currently only order = 1 is supported.

    Returns
    -------
    Fs: List[sp.Matrix]
        List of matrices representing the log-linearized model.

    Notes
    -----
    Convert the non-linear model to its log-linear approximation using a first-order Taylor expansion around the
    deterministic steady state. The specific method of log-linearization is taken from ..[1]

    .. math::
        F_1 T y_{t-1} + F_2 @ T @ y_t + F_3 @ T @ y_{t+1} + F4 \varepsilon_t = 0

    Where T is a diagonal matrix containing steady-state values on the diagonal. Each of F1, F2, F3, and F4 are the
    Jacobian matrices of the model equations with respect to the variables at time t-1, t, t+1, and the exogenous shocks,
    respectively. Evaluating the matrix multiplications in the expression above obtains:

    .. math::
        A y_{t-1} + B y_t + C y_{t+1} + D \varepsilon = 0

    Matrices A, B, C, and D are returned by this function.

    References
    ----------
    [1] gEcon User's Guide, page 54, equation 9.9.
    """
    if order != 1:
        raise NotImplementedError(
            "Only order = 1 linearization is currently implemented."
        )

    ss_variables = [x.to_ss() for x in variables]
    lags, now, leads = make_all_variable_time_combinations(variables)

    eq_vec = sp.Matrix(equations)
    A, B, C, D = (
        eq_to_ss(eq_vec.jacobian(var_group)) for var_group in [lags, now, leads, shocks]
    )
    not_loglin_var = sp.IndexedBase("not_loglin_variable", shape=(len(variables),))
    T = sp.diag(
        *[ss_var ** (1 - not_loglin_var[i]) for i, ss_var in enumerate(ss_variables)]
    )

    Fs = [A @ T, B @ T, C @ T, D]
    return Fs, not_loglin_var


def compile_linearized_system(
    variables: list[TimeAwareSymbol],
    equations: list[sp.Expr],
    shocks: list[TimeAwareSymbol],
    parameters: list[sp.Symbol],
    backend: BACKENDS = "numpy",
    return_symbolic: bool = False,
    cache: dict | None = None,
    **kwargs,
):
    cache = {} if cache is None else cache

    ss_variables = [x.to_ss() for x in variables]
    outputs, not_loglin_var = linearize_model(variables, equations, shocks)

    inputs = parameters + ss_variables + [not_loglin_var]

    f_linearize, cache = compile_function(
        inputs,
        outputs,
        backend=backend,
        cache=cache,
        return_symbolic=return_symbolic,
        **kwargs,
    )

    return f_linearize, cache


def solve_policy_function_with_cycle_reduction(
    A: ArrayLike,
    B: ArrayLike,
    C: ArrayLike,
    D: ArrayLike,
    max_iter: int = 1000,
    tol: float = 1e-8,
    verbose: bool = True,
) -> tuple[ArrayLike, ArrayLike, str, float]:
    """
    Solve quadratic matrix equation of the form $A0x^2 + A1x + A2 = 0$ via cycle reduction algorithm of [1] to
    obtain the first-order linear approxiate policy matrices T and R.

    Parameters
    ----------
    A: Arraylike
        Jacobian matrix of the DSGE system, evaluated at the steady state, taken with respect to past variables
        values that are known when decision-making: those with t-1 subscripts.
    B: ArrayLike
        Jacobian matrix of the DSGE system, evaluated at the steady state, taken with respect to variables that
        are observed when decision-making: those with t subscripts.
    C: ArrayLike
        Jacobian matrix of the DSGE system, evaluated at the steady state, taken with respect to variables that
        enter in expectation when decision-making: those with t+1 subscripts.
    D: ArrayLike
        Jacobian matrix of the DSGE system, evaluated at the steady state, taken with respect to exogenous shocks.
    max_iter: int, default: 1000
        Maximum number of iterations to perform before giving up.
    tol: float, default: 1e-7
        Floating point tolerance used to detect algorithmic convergence
    verbose: bool, default: True
        If true, prints the sum of squared residuals that result when the system is computed used the solution.

    Returns
    -------
    T: ArrayLike
        Transition matrix T in state space jargon. Gives the effect of variable values at time t on the
        values of the variables at time t+1.
    R: ArrayLike
        Selection matrix R in state space jargon. Gives the effect of exogenous shocks at the t on the values of
        variables at time t+1.
    result: str
        String describing result of the cycle reduction algorithm
    log_norm: float
        Log L1 matrix norm of the first matrix (A2 -> A1 -> A0) that did not converge.
    """

    # Sympy gives back integers in the case of x/dx = 1, which can screw up the dtypes when passing to numba if
    # a Jacobian matrix is all constants (i.e. dF/d_shocks) -- cast everything to float64 here to avoid
    # a numba warning.
    T, R = None, None

    # A, B, C, D = A.astype('float64'), B.astype('float64'), C.astype('float64'), D.astype('float64')

    T, result, log_norm = nb_cycle_reduction(A, B, C, max_iter, tol, verbose)

    if T is not None:
        R = nb_solve_shock_matrix(B, C, D, T)

    return T, R, result, log_norm


def solve_policy_function_with_gensys(
    A: ArrayLike,
    B: ArrayLike,
    C: ArrayLike,
    D: ArrayLike,
    tol: float = 1e-8,
    verbose: bool = True,
) -> tuple:
    n_eq, n_vars = A.shape
    _, n_shocks = D.shape

    lead_var_idx = np.where(np.sum(np.abs(C), axis=0) > tol)[0]
    eqs_and_leads_idx = np.r_[np.arange(n_vars), lead_var_idx + n_vars].tolist()

    n_leads = len(lead_var_idx)

    Gamma_0 = np.vstack(
        [np.hstack([B, C]), np.hstack([-np.eye(n_eq), np.zeros((n_eq, n_eq))])]
    )

    Gamma_1 = np.vstack(
        [
            np.hstack([A, np.zeros((n_eq, n_eq))]),
            np.hstack([np.zeros((n_eq, n_eq)), np.eye(n_eq)]),
        ]
    )

    Pi = np.vstack([np.zeros((n_eq, n_eq)), np.eye(n_eq)])

    Psi = np.vstack([D, np.zeros((n_eq, n_shocks))])

    Gamma_0 = Gamma_0[eqs_and_leads_idx, :][:, eqs_and_leads_idx]
    Gamma_1 = Gamma_1[eqs_and_leads_idx, :][:, eqs_and_leads_idx]
    Psi = Psi[eqs_and_leads_idx, :]
    Pi = Pi[eqs_and_leads_idx, :][:, lead_var_idx]

    # Is this necessary?
    g0 = -np.ascontiguousarray(Gamma_0)  # NOTE THE IMPORTANT MINUS SIGN LURKING
    g1 = np.ascontiguousarray(Gamma_1)
    c = np.ascontiguousarray(np.zeros(shape=(n_vars + n_leads, 1)))
    psi = np.ascontiguousarray(Psi)
    pi = np.ascontiguousarray(Pi)

    G_1, constant, impact, f_mat, f_wt, y_wt, gev, eu, loose = gensys(
        g0, g1, c, psi, pi
    )

    return G_1, constant, impact, f_mat, f_wt, y_wt, gev, eu, loose


def residual_norms(B, C, D, Q, P, A_prime, R_prime, S_prime):
    norm_deterministic = linalg.norm(A_prime + B @ R_prime + C @ R_prime @ P)

    norm_stochastic = linalg.norm(B @ S_prime + C @ R_prime @ Q + D)

    return norm_deterministic, norm_stochastic


def statespace_to_gEcon_representation(self, A, T, R, variables, tol):
    n_vars = len(variables)

    state_var_idx = np.where(
        np.abs(T[np.argmax(np.abs(T), axis=0), np.arange(n_vars)]) >= tol
    )[0]
    state_var_mask = np.isin(np.arange(n_vars), state_var_idx)

    n_shocks = self.n_shocks
    shock_idx = np.arange(n_shocks)

    PP = T.copy()
    PP[np.where(np.abs(PP) < tol)] = 0
    QQ = R.copy()
    QQ = QQ[:n_vars, :]
    QQ[np.where(np.abs(QQ) < tol)] = 0

    P = PP[state_var_mask, :][:, state_var_mask]
    Q = QQ[state_var_mask, :][:, shock_idx]
    R = PP[~state_var_mask, :][:, state_var_idx]
    S = QQ[~state_var_mask, :][:, shock_idx]

    A_prime = A[:, state_var_mask]
    R_prime = PP[:, state_var_mask]
    S_prime = QQ[:, shock_idx]

    return P, Q, R, S, A_prime, R_prime, S_prime
